{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Sampling Methods to solve a Linear Regression Problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Metropolis Hastings Sampling\n",
    "\n",
    "## - Hamiltonian Monte Carlo\n",
    "\n",
    "## - Automatic Relevance Detection with HMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst regression problems can be solved in closed form, we will demonstrate sampling methods to sample from the joint posterior of our hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy              as np\n",
    "import pandas             as pd\n",
    "import scipy.stats        as stats\n",
    "import scipy.spatial      as spatial\n",
    "import seaborn            as seabornInstance \n",
    "import matplotlib.pyplot  as plt\n",
    "import statsmodels.api    as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn              import metrics\n",
    "from tqdm.notebook        import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will solve a regression problem where we assume a mean zero Gaussian prior on the weights with precision alpha and a mean zero Gaussian prior on the noise with precision beta.\n",
    "\n",
    "We will work on the Energy Efficiency dataset which has 8 predictors + intercept/bias.\n",
    "\n",
    "Preprocessing has been performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ee-train.csv\", \"rb\") as csvfile:\n",
    "    train = pd.read_csv(\"ee-train.csv\",low_memory=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ee-test.csv\", \"rb\") as csvfile:\n",
    "    test = pd.read_csv(\"ee-test.csv\",low_memory=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.mean(train, axis = 0)\n",
    "train_std   = np.std(train,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = (train - train_means)/train_std\n",
    "train_norm.loc[:,'Heating Load'] = train.loc[:,'Heating Load']\n",
    "train_norm.insert(0,'Constant',1)\n",
    "n_features = train_norm.shape[1]\n",
    "test_norm = (test - train_means)/train_std\n",
    "test_norm.loc[:,'Heating Load'] = test.loc[:,'Heating Load']\n",
    "test_norm.insert(0,'Constant',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_norm.iloc[:,:n_features-1]\n",
    "y_train = train_norm.iloc[:,n_features-1]\n",
    "x_test  = test_norm.iloc[:,:n_features-1]\n",
    "y_test  = test_norm.iloc[:,n_features-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis - Hastings Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_star = lambda x: stats.multivariate_normal.rvs(size=1, mean=x, cov = 0.01*np.eye(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_star(x, X, Y):\n",
    "    \n",
    "    alpha     = x[0]\n",
    "    \n",
    "    beta      = x[1]\n",
    "    \n",
    "    w         = x[2:]\n",
    "    \n",
    "    alpha     = np.exp(alpha)\n",
    "    \n",
    "    beta      = np.exp(beta)\n",
    "    \n",
    "    n,m       = X.shape\n",
    "    \n",
    "    first     = -(n/2)*np.log(2*np.pi/beta)  - (beta/2)*((Y - X @ w)**2).sum()\n",
    "    \n",
    "    second    = -(m/2)*np.log(2*np.pi/alpha)  - (alpha/2)*(w**2).sum()\n",
    "    \n",
    "    pdf       = first + second\n",
    "    \n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh        = sampling.MH(p_star, q_star, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples   = mh.sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = mh.estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha   = np.exp(estimates[0])\n",
    "beta    = np.exp(estimates[1])\n",
    "weights = estimates[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve a RMSE on the test of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.863357408155559"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(np.square(x_test @ weights - y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamiltonian MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_func(x, x_train, y_train):\n",
    "    \n",
    "    alpha     = np.exp(x[0])\n",
    "    \n",
    "    beta      = np.exp(x[1])\n",
    "    \n",
    "    w         = np.array(x[2:])\n",
    "\n",
    "    n,m       = x_train.shape\n",
    "    \n",
    "    mat       = y_train.T @ y_train - w.T @ x_train.T @ y_train - y_train.T @ x_train @ w + w.T @ x_train.T @ x_train @ w\n",
    "    \n",
    "    pdf       = -(n/2)*np.log((2*np.pi)/beta)  - (beta/2)*(mat) \\\n",
    "                +(m/2)*np.log(alpha/(2*np.pi)) - (alpha/2)*(w.T @ w)\n",
    "    \n",
    "    return -pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_grad(x, x_train, y_train):\n",
    "    \n",
    "    alpha = np.exp(x[0])\n",
    "    \n",
    "    beta  = np.exp(x[1])\n",
    "    \n",
    "    w     = np.array(x[2:])\n",
    "    \n",
    "    n,m   = x_train.shape\n",
    "    \n",
    "    g = np.empty(11)\n",
    "    \n",
    "    g[0] = 0.5*m - 0.5*alpha*(w.T @ w)\n",
    "    \n",
    "    g[1] = 0.5*n - 0.5*beta*((y_train - x_train @ w)**2).sum()\n",
    "    \n",
    "    g[2:] = -alpha*w - 0.5*beta*(-(x_train.T @ y_train) \\\n",
    "                                 - (y_train.T @ x_train) \\\n",
    "                                 + 2*(x_train.T @ x_train @ w))\n",
    "    \n",
    "    return -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc = sampling.Hamiltonian(e_func, e_grad, 11, epsilon0 = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance Rate: 1.0\n"
     ]
    }
   ],
   "source": [
    "samples = hmc.sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha   = np.exp(samples[-1,0])\n",
    "beta    = np.exp(samples[-1,1])\n",
    "weights = samples[-1,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve a RMSE on the test of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.854137588874011"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(np.square(x_test @ weights - y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Relevance Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change our prior on the weights to a Gaussian prior for each weight with different precision hyper-parametrs. We can then sample from this larger joint posterior to determine which features are relevant. High precision indicated low variance and therefore weights likely close to zero (mean zero prior assumed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_func(x, x_train, y_train):\n",
    "    \n",
    "    alphas     = np.exp(x[0:9])\n",
    "    \n",
    "    beta      = np.exp(x[9])\n",
    "    \n",
    "    w         = np.array(x[10:])\n",
    "\n",
    "    n,m       = x_train.shape\n",
    "    \n",
    "    mat       = y_train.T @ y_train - w.T @ x_train.T @ y_train \\\n",
    "                - y_train.T @ x_train @ w + w.T @ x_train.T @ x_train @ w\n",
    "    \n",
    "    pdf       = -(n/2)*np.log((2*np.pi)/beta)   - (beta/2)*(mat) \\\n",
    "                + 0.5*np.sum(np.log(alphas)) - 0.5*np.sum(alphas*(w**2)) - (m/2)*np.log(2*np.pi)\n",
    "    \n",
    "    return -pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_grad(x, x_train, y_train):\n",
    "    \n",
    "    alphas = np.exp(x[0:9])\n",
    "    \n",
    "    beta  = np.exp(x[9])\n",
    "    \n",
    "    w     = np.array(x[10:])\n",
    "    \n",
    "    n,m   = x_train.shape\n",
    "    \n",
    "    g     = np.empty(19)\n",
    "    \n",
    "    g[0:9]  = (1/2)*(1 - alphas*(w**2))\n",
    "    \n",
    "    g[9]    = 0.5*n - 0.5*beta*((y_train - x_train @ w)**2).sum()\n",
    "    \n",
    "    g[10:]  = -alphas*w - 0.5*beta*(-(x_train.T @ y_train) \\\n",
    "                                 - (y_train.T @ x_train) \\\n",
    "                                 + 2*(x_train.T @ x_train @ w))\n",
    "    \n",
    "    return -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_ard = sampling.Hamiltonian(e_func, e_grad, 19, epsilon0 = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance Rate: 1.0\n"
     ]
    }
   ],
   "source": [
    "ard_samples = hmc_ard.sample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha   = np.exp(ard_samples[-1,0:9])\n",
    "beta    = np.exp(ard_samples[-1,9])\n",
    "weights = ard_samples[-1,10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve a RMSE on the test of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8667631203122403"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(np.square(x_test @ weights - y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With alphas of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.58888581e-07, 5.15295127e-03, 1.73903967e-02, 4.23730893e-02,\n",
       "       8.57967475e+01, 1.65612989e-05, 1.32854405e+01, 1.49081472e-01,\n",
       "       3.80070277e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And therefore features variances of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04287403e+06, 1.94063547e+02, 5.75030011e+01, 2.35998842e+01,\n",
       "       1.16554535e-02, 6.03817375e+04, 7.52703682e-02, 6.70774165e+00,\n",
       "       2.63109235e-01])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/alpha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
